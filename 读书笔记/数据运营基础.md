随着信息化时代的到来,数据存储成本的不断下降,企业数据的总量正在不断攀升,这些数据是企业的重要资源。从电商网站的“猜你喜欢”等个性化推荐，商家促销活动的精准营销，到智慧城市建设的一站式服务等应用场景，大数据已经逐渐渗透到我们工作生活的方方面面。  
大数据领域涵盖了数据采集、数据存储、数据处理、数据挖掘、数据分析、数据呈现等技术手段，企业的海量数据只有经过这些技术手段才能创造出价值。如何有效地利用企业经营生产过程中产生的数据，并从这些数据中提取出有用的模式对其进行分析、挖掘、应用已经成为各公司迫切需求。  
企业中数据从产生到应用依次需要经过数据源层、数据仓库层、数据建模层、数据应用层，从原始的海量数据经过各层的清洗、建模、挖掘之列的加工后逐渐支持到上游的应用环节。  
1. 数据源  
  数据种类通常包括企业内部的OA数据、财务数据、BD数据、业务数据、日志数据、埋点数据和第三方数据。数据需要经过抽取、转换和装载，即经过ETL后才可以存储在数据仓库内，为数据分析奠定基础。  
  - OA数据：企业内部办公系统相关数据。
  - 财务数据：包括现金流、资产、负债、成本等数据，财务数据是企业数据的重要部分。
  - 业务数据：即用户在Web、APP、H5三端与产品发生操作行为而产生的业务类数据，如下单、收藏、支付等行为。
  - 日志数据：用户访问Web、APP、H5三端过程中留下的行为日志，例如用户在某个时间方位了web上的一篇文章，即留下了该条行为日志。
  - 埋点数据：用户在Web、APP、H5三端单击行为带来的相关数据，例如用户在APP端单击了某个页面的某个banner位，即上报该条行为日志。
  - 外部第三方数据：包括爬虫得到的外部第三方数据和政府、行业等公开的市场数据。  

2. 数据仓库
  数据仓库的数据包括元数据和经过ETL的业务数据，元数据是关于数据的数据，主要包括数据源的描述。数据仓库一般采用分层设计，具体包括ODS层、DW层、DM层数据。数据经过层层加工屏蔽掉了底层负责的业务逻辑，将尽可能简单、完整地在接口层呈现业务数据，最终为业务人员的数据提取和分析提供支持。  
  - ODS层（operation data store）：原始数据层，数据来源是各业务系统的源数据，是操作型环境与数据仓库的隔离。在从操作型环境到数据仓库环境抽取的过程中会对数据做格式解析、多数据源的合并、设置字段默认值等ETL操作。  
  - DW层（data warehouse）：数据仓库层，对ODS层数据做进一步的建模加工，提供统计汇总数据，是根据企业信息需求而非部门业务需求而建立的。数据仓库为非常大的群体提供服务，因此在面向业务主体层面而言，性能和便捷性不如数据集市层。  
  - DM层（data Markt）：数据集市层，该层数据来自DW层，为各业务单元定义的集市，输出相关的主体宽表。提供各主体业务的明细层数据，主要用于数据分析人员查询。数据分析。  
  一般企业的数据部门为了方便经营分析人员对业务各板块分析、为了搭建大数据管理平台，会对散落在数仓中各业务线的有价值的表进行梳理，整理出一份数据字典。该数据字典中明确了每个业务主体所包含的表，以及各张表的业务含义、获取方式和关联规则。数据分析人员借助数据字典可以更好地了解公司的全景数据，明确数据的分布和含义。

3. 数据建模
  数据经过数据仓库的层层清洗、加工后到达数据建模层，数据分析人员对数据进行查询与分析，数据挖掘人员对数据进行深度的价值挖掘。

4. 数据应用
  数据应用层是数据价值产生的出口，在数据分析层经过数据挖掘人员对数据进行数据挖掘、用户画像建模、推荐算法的指定，可以支持业务应用层面向用户的智能营销和个性化内容推荐的功能。




### 数据运营的岗位职责
  数据部门常见的职能架构包括分散型数据架构（各业务中心下单独设立数据部门）和集中型数据架构（企业数据工作集中在一个中心部门）。集中型数据架构可有效解决数据源和数据口径的一致性问题，保证数据质量和及时性，因此这种架构较为常见。  
  从工作岗位上看，数据团队为各业务部门的数据支持方，团队内成员主要从事数据采集、清理、分析、策略、建模等工作，支撑整个运营体系朝精细化方向发展。常见的岗位包括：数据分析师、算法工程师、爬虫工程师、ETL工程师、数据挖掘工程师等。从工作内容来分，我们将其归纳为数据治理、数据分析挖掘、数据产品三个层次：  
  - 数据治理：数据治理负责数据系统的架构规划、数据的标准和规范化作业、数据的权限管理，保证数据的安全性和可用性，定义各业务口径的数据标准，构建数据集市和底层数据架构，输出支持到分析人员应用的数据字典。
  - 数据分析挖掘：数据分析师数据运营的重点工作，其核心是业务方向的数据分析支持。主要包括：  
    1. 对业务活动进行效果评估以及异常分析，如异常订单分析、异常流量分析、挖掘业务机会点，给予运营方建议及指导。
    2. 手机整理各业务部门的数据需求，搭建数据指标体系，定期向业务部门提交数据报表，包括日报、周报、月报等。
    3. 数据价值挖掘，如基于用户行为数据建立用户画像、建立RFM模型对客群进行聚类营销
    4. 辅助管理层决策，对问题进行定位，输出可行性建议，辅助管理层进行决策。
  - 数据产品：负责梳理各部门对数据产品的需求，规划报表并优化报表，协调数据仓库的开发资源保证项目按时上线。将数据分析部门建立的挖掘模型、用户画像等数据模型做成可视化产品输出。企业内部常见的数据产品包括数据管理平台和自主数据提取平台。其中数据管理平台支持运营日报查看、实时交易数据查看、业务细分数据查看；自主数据提取平台满足业务方对更细微业务数据的需求，解放数据提取人员的重复性工作。


### 必须掌握的技能
  Excel、SQL、Python、PPT及业务理解能力


## 数据驱动运营
#### 在数据驱动运营中,数据分析师如何做好分析,以辅助运营决策.
在数据分析日常工作中经常会存在这种情况,老板说需要看一下某新上线业务的情况,数据分析师接到需求之后匆匆写完SQL脚本把一堆业务数据提取出来并简单展示交给老板，然后被打回来重做。领导说：“新业务上线之后我想看一下用户活跃和老业务xxx的对比情况。”
或者这种情况，运营同事提了一个数据提取的需求，在数据分析师废了很大力气把相关数据的表从线上业务数据库提取到数据仓库，并把相关数据提取出来之后，运营却说要修改需求，于是所有的事情需要重新再来一遍。  
这是新手常犯的错误，归根到底是没有和看报告的人进行有效地沟通，没有明确分析的目标。
说到明确目标，这又涉及到看报告人的身份。
- 管理层，他们最为关心自己最近做的重大决策最终反映到哪些指标上？这些指标的相互关系是怎样的？业务的全局变化如何？与过去相比哪些进步？目前哪些执行动作需要调整，对应的指标是什么。
- 运营方，他们最关心最近的活动效果怎么样？banner位怎么定价比较合理？一些运营活动是否可以持续提升效果？是否需要将运营方法持续固化为产品模块等一些和运营举措相关的。
- 产品方，他们关心的是上线的功能或者设计对用户有没有用？用户有没有去使用？如果用户使用了，如何让产品变得更好用？如果没有使用，分析用户没有使用的原因是什么？是产品设计有问题？流程走不通还是用户不明白怎么用？
明确目标，需要数据分析师在分析之前就进行有效地沟通。先明确这次的分析到底需要达成什么目的，在了解业务的基础上，明确应该从什么角度去切入，应该从哪些指标着手，再去企鹅人哪些数据现阶段已经有，哪些指标现阶段需要推动去建设，然后统筹规划，根据目前已经有的指标，故事线应该如何铺设。  
说到底，常见的数据分析目标主要分为三大类，即解决是什么，为什么，做什么的问题。解决是什么的问题，一般用描述性统计方法就可以解决。解决为什么的问题，则需要严谨的逻辑思维对具体问的做数据分析，找出原因；解决做什么的问题，则需要通过具体的分析，提供可选的建议，最后交给运营或者管理层来拍板选择相关的可行方案。这三大类分析目标最终都会聚集到一点，对业务及业务流程的了解，只有对业务完全清楚，才知道如何描述是什么，才知道应该从什么角度去切入分析为什么，才知道提供的解决方案能解决业务流程的那个问题，最终如何影响全局，达到效果。

#### 目标分解与聚焦
一、 付费用户客单价下降原因定位
  在互联网




#### AARRR模型
产品存在的目的主要是为了实现盈利，那么如何实现盈利的目标呢？这是个很大的问题，我们首先要将这个目标拆解为很多小的可执行的目标。
根据增长模型，可将产品的营收路径拆分为激活→注册→留存→下单→传播。其中激活主要是流量运营在负责，用户运营会贯穿接下来的流程，内容运营主要负责生产优质的内容来提高用户的粘性，从而提高留存，抖音就是靠优质内容来锁定用户的；主线运营主要负责主营业务的产品路径，优化转化节点，提高转化。
增长模型详细步骤：
- 激活：这是流量来源的必经动作，只有有足够多的用户来，才能对这些用户进行转化。众所周知，互联网获客成本比较高，如果不清楚渠道的流量质量，就有可能化了钱，却没有获取到质量比较好的用户。对于这一块，用户触达的基本分析就是对用户拉远渠道进行分析，在不依靠自然流量的情况下，哪些合作、投放渠道对产品更合适。
- 注册：如果用户只是点进来就走了，则这个流量对产品并没有什么作用。只有通过高质量的内容，合适的产品功能切合用户的需求，用户才会有进一步了解产品的欲望，才会有转化的下一步操作——注册。因此通过渠道将用户引入平台后，还是远远不够的，需要进一步关注用户是否进一步注册转化，从注册流程上看是否存在需要优化的细节点。
- 留存：获客成本比较高，因此不能一味花钱去不断获取新流量，同时也需要维系老用户，让进来的用户能对产品产生依赖，产品能切合用户需求，让用户持续不断地来用我们的产品。因此提升留存一方面需要满足用户需求，另一方面需要优化用户体验。在优化过程中可通过用户分群进行精细化运营，将精准内容推送给有特定需求的用户，提高用户对产品的满意度。数据可以通过追踪用户行为，来分析哪些行为可以激发用户持续访问产品，如何促使这些行为的发生，并通过用户生命周期的研究，对沉默用户进行识别，让运营通过运营手段对这批用户进行唤醒；对流失用户进行标记，让运营通过推送、发放优惠等方式进行召回。
- 营收：用户是收入的前提，只有产品满足用户的需求，使用户认同产品的价值，才会促使用户向付费转化。要让产品持续稳定地运营下去，就需要通过一系列运营手段，让新用户持续地向付费转化，让老用户持续付费。用户运营的基础，是对用户足够了解，足够熟悉，而数据就是帮运营了解用户的所有属性，让用户不断向营收进行转化。
- 传播：只有用户对产品高度认可及对产品功能高度依赖，才会愿意将产品分享或推荐给其他人。而在分享或推荐过程中，又扩大了流量的来源，形成了良性循环，最终不断地将用户往营收用户进行转化。


### 流量运营分析
流量运营包括哪些内容？
- 从流量营销的角度看，主要分析对象是访问用户，他们能帮助了解用户的量级、用户的偏好、用户的来源和去向，能帮助我们了解访问用户在流量中的行为及不同流量渠道之间的关系。
- 从分析队形的逻辑结构来看，我们主要看产品的健康状况，页面的表现，注册到下单的流程是够顺畅。
- 从流量运营的角度看，主要看产品表现来进行资源预算的合理分配，而产品的表现需要通过一系列指标来追踪。

在明确流量运营的整体规划后，我们可以先把营收作为最终目标对其进行拆解，首先需要有足够的优质目标用户来访问，这就细分了不同流量来源渠道的质量，需要查看用户的来源及去向，总结用户对产品的需求，然后要有合理的产品结构跟页面布局来吸引客户，满足用户需求，这里可以看用户的具体行为，如访问路径等。通过追踪用户的一系列行为，在转化的每个过程都设立合适的指标追踪，并通过分析找出有问题的环节进行迭代与更新。
总之，通过不同视角来对流量进行分析，对一下方面有所助益：
①观察流量规律，区分不同流量的质量，关闭异常渠道，优先选择优质渠道，节约渠道推广成本。
②根据用户路径分析，寻找产品存在问题的环节及改进的方案，及时迭代更新
③对不同流量的用户进行细分，进行精准的市场定位
④通过设定指标，追踪流量情况，衡量流量推广活动效果或者渠道优化效果分析。



#### 流量分析
流量是所有用户的归口，是所有后续行为的源头。流量的质量及量级直接关系到后续的转化好不好，用户规模怎么样，用户层级如何，因此流量分析非常重要。
1. 流量来源分析

流量主要可以分为广告流量、SEO流量、SEM流量、搜索流量、直接流量及其他流量来源。
广告流量主要是指访问者通过单击其他网站的链接来访问我们网站的流量。
SEO流量是指通过网站排名技术，把网站排名提前，被用户搜索到带来的免费流量。
SEM流量是指搜索引擎营销带来的流量，即搜索引擎根据用户使用习惯，和用户搜索的信息推送营销信息带来的流量。
直接流量是指用户直接输入域名访问网站产生的流量。
这些流量在埋点日志中都会有相应记录，方便分析师识别。
比如某天的流量上涨了，想找到具体是哪些流量变化，这时可以根据埋点区分的字段来将流量分类，并个前一时期进行比对，从而得出是哪一类流量发生了变化。


2. 虚假流量区分
流量来源中有几类是需要花钱购买，涉及成本，所以评估付费流量的效果，评估付费流量对ROI的影响非常重要。流量的付费方式一般分为按单击付费、按用户激活付费。按用户注册付费、按用户下单付费等。我们如何评估流量的效果呢？首先我们需要识别虚假流量，什么是虚假流量呢？
一般虚假流量分为以下几个维度：
  1. 分时分布。可以看一下各个渠道流量来源的分时分布，正常来说一般的网站会有一个时间段的明显区分，比如白天流量多，晚上流量少，或者下班时间跟午休时间会有流量高峰期。而虚假流量如果是用控制程序带来的单击，可能不会考虑分时的影响，这种时候没有明显的时间分布排列的流量需要重点关注。
  2. 页面的跳出率。跳出率是衡量页面质量的指标（跳出率是指在只访问了入口页面（例如网站首页）就离开的访问量与所产生总访问量的百分比），这里用来衡量渠道的流量质量。比如某个时间段或某个渠道的跳出率非常高，那么这部分流量需要重点关注。
  3. 流量的用户留存。若用户的留存率非常不理想，则这部分流量也极有可能是虚假流量。
  4. 风控规则。若同一个设备某段时间内登陆了5个账户，这些流量需要重点关注。
  5. 对营收的转化。如果一个渠道引入的流量对营收的转化率非常小，但流量居高不下，这时就需要重点关注。
虚假流量的识别方法非常多，但虚假流量也在不断模仿真实流量，所以虚假流量的识别方法可能需要多次校验，多维度分析。


3. 流量波动的常见原因
对于流量来说，经常会存在流量变化的情况，而追踪流量变化的原因，对于后续的流量运营更能有的放矢。下面我们根据流量的分类来分别看一下不同场景下相关流量类型的流量变化因素。
  1. 广告流量
    广告流量是通过广告合作，比如在合作产品有广告位，或其他引流合作模式带来的流量。这块流量变化的主要原因有：
      1. 广告位置的变化，比如合作方原来把产品放在角落，增加了广告费后，将产品放在了首页最显眼的地方，用户能够第一眼就看到产品。
      2. 合作产品内嵌的入口文字或内容变化，原来可能只是一个简单的入口，后来针对合作网站的用户群体，将产品入口设置为符合用户群体习惯的界面，或者加了文字进行指导，导致合作方转化增加，流量加大。
      3. 合作方本身流量基数增大，虽然转化率没有发生变化，但是流量基数增大，使得访问的用户增多。
      4. 链接形式变化，图片链接和文字链接带来的转化是有区别的，这个需要通过埋点日志细分看一下。
  2. SEO流量
    SEO流量及SEM流量可以统称为搜索流量，区分方式是，一个免费搜索关键词带来的，一个是付费的搜索关键词带来的，SEO流量变化原因主要有：
      1. 关键词，比如产品业务的核心关键词和拓展关键词增加，或者关键词更符合用户的搜索习惯了，则关键词带来的流量会相应增加。
      2. 排名与外链，排名的变化直接影响流量的变化，比如我们搜索时一般会直接选择top多少的页面点进去，很少会一页一页翻不是首页的内容，所以一般企业会提升关键词排名，而影响排名的主要因素是外链，这些外链都需要在日志中有记录，好追踪不同外链的质量。
      3. 竞争对手，竞争对手的优化策略也会影响我们的流量。
      4. 网站内部调整，比如流量增加可能是网站进行了优化，包括网站结构、URL、内链布局、SEO基本元素、用户体验优化等。
      5. SEM的策略：因为SEO与SEM都属于搜索引擎导流流量，对于同一个关键词而言，SEM的排名会高于SEO，SEM流量增加了，SEO的流量会相应下降。
  3. SEM流量
    SEM流量是通过购买关键词及对搜索结果竞价而从搜索引擎获取的流量，影响SEM流量的变化的原因有：
      1. 关键词的定价策略，关键词的价格会直接影响广告的排名与位置，从而影响流量。
      2. 关键词的匹配方式，关键词的匹配方式分为精准匹配、词组匹配、模糊匹配，SEM的关键词的匹配方式会直接影响流量，比如搜索女装，若匹配方式是精准匹配，那么只有搜索词为女装时方可对应到广告位。
      3. 投放时间，凌晨的时候，访问者大多在休息，其他时间才是用户比较活跃的时间，故选定的投放时间对流量影响较大。
      4. 广告投放地域，一般而言，投放的地区越多，和单独投放某个地区相比，引流效果肯定不一样，因为增加投放区域会有新的流量池来转化引流。
      5. 竞争对手SEM策略，当竞争对手也买了一样的关键词时，会影响流量的转化。
    由于SEM流量需要付费投放，公司一般会针对SEM渠道流量搭建日常专题分析报表持续跟踪投放效果。
  4. 直接流量
    如果直接流量在某一段时间内变化较大，此时我们需要定位具体的流量来源及流量时区分步，可能的原因有：
      1. 产品请了明星代言，吸引用户来访问了产品。
      2. 有特殊热点事件，比如很多品牌会追着热点发布自己产品的方案，吸引用户关注。
      3. 比如发红包、做测试、送优惠券、打折促销等活动，若这些活动的影响力足够大，会对产品或网站整体的流量有比较大的影响。

#### 解读PV、UV
  PV即页面浏览量，也就是页面被加载的总次数，每一次页面被加载，PV就会加1。比如你访问淘宝，看了页面A，点击了刷新，然后看到旁边另一款笔记本的推荐，点了页面B，看完之后发现B不和心意，又返回到了页面A，发现另一款也不好，直接关闭离开了，则你这次的PV是4次。
  UV是唯一身份访问者，即在指定时间内不重复的访问者人数，也称为某段时间去重的用户数。该指标主要由以下因素影响：
    1. JavaScript被禁用时，GA的代码无法工作，无法识别这个用户。
    2. cookie，cookie被清除后，会再记录称为一个UV。
  PV和UV一般用来衡量网站的流量情况，数据大，说明流量多，人均PV越大，说明每个用户来到对应渠道之后流量页面增多，用户对内容越发感兴趣。


  要统计流量数据，先要了解埋点日志结构，及日志中一些常用指标及常用指标的作用范畴。埋点日志经过解析，会完全记录用户的每一次操作。经过解析日志数据后，主要得到以下字段用于经营分析：
    1. 时间戳：埋点日志里会记录用户的访问时间，这个时间记录了用户进入产品或者网站的所有时间点，通过时间的限定，可以看出流量的不同时间分布，及用户的按时间先后顺序访问路径。
    2. URL：当前页面的链接。
    3. referral-url：上一级页面链接，通过该参数可以分析用户单击跳转的路径。
    4. session-id：设备id，用于识别用户登录设备的id号，当做用户作为游客登录时，由于没有注册账号，因此使用设备id用于识别用户身份。
    5. user-id：用户id，用于识别用户在该平台上的唯一身份。



#### 跳出率分析
跳出率是指某一段时间内只访问了一页就离开的访问量与所产生的总访问量的百分比。该指标一般用来衡量流量来源用户与网站内容的匹配程度，内容的匹配程度和跳出率成反比，即内容匹配程度越高，跳出率越低。比如某个用户通过某链接进入产品的页面，看到第一个页面就非常反感而离开了。这就是一次跳出访问。当有比较多的用户重复该用户的行文，就会形成较高的跳出率。
既然跳出率一般是用来衡量来源用户与网站内容的匹配程度的，对于像这种需要靠转化来提高营收的网站来说，高跳出率是个负面指标。这个指标在侧面也显示出用户的流失率。
这个质保可以细分不同的渠道，来看不同渠道的跳出率，并针对性地做出优化，也可以用来看不同流程的关键节点的跳出率，看是否哪个流程有问题，是否可以优化。


#### 漏斗图分析
漏斗图是通过对业务的各个关键环节的描述，来衡量各个环节的业务表现。从漏斗图可以非常直观地看到各个业务的转化程度。从某种意义来说，漏斗图是路径分析的特殊应用，主要是针对关键路径的转化分析。由于互联网行业的日志数据记录了用户的所有访问行为，因此漏斗转化分析在互联网行有着广泛的应用，主要包括以下两点：
1. 业务的关键节点分析
  以淘宝的购买为例子来讲一下，在淘宝购买一件商品需要经过以下几个步骤： 浏览→加入购物车→付款→收货→评价，这些步骤一路走下来，势必用户越来越少。从浏览的用户群体中，有多少用户加入了购物车，之后付款的用户又有多少，再到收货的用户群体比率，评价比率，在购买商品的关键业务环节上，各个指标均直观展示出来了，之后可以长期追踪这些指标，如果移动较大，说明那个环节转化出了问题，这个时候可以定位具体的环节，在细分涉及环节的影响，追踪原因，给运营提供参考。
2. 用于追踪流量运营转化率
  在流量导入→营收转化的过程中，漏斗图可追踪各个节点的转化情况，定位异常转化节点，及时调整运营策略。比如某一周发现导入的流量在正常的增长范围内，注册率也在正常的增长范围，但是活跃度下降的厉害，这个时候就需要看具体的渠道活跃度，结合渠道获客成本结算方式（如果是按激活来结算的，还是按注册来结算的，根据风控规则来看一下渠道的登陆设备是否存在作弊的情况）定位具体原因。
  或者分析下每个转化节点转化减少的原因，尽量提高每一步的转化。比如下单率，可以看一下活跃的但没有下单的用户都去做什么了，有没有可能在用户感兴趣这部分的内容上做文章，从而提高转化。比如某电商平台入驻了很多商家，部分用户进入商家页面后悔转去内容平台看用户分享的内容，此时如果在用户分享的内容内嵌相关商品的购买界面 ，用户有兴趣的话可以一键跳转，然后用数据追踪，调整之后转化率的变化情况。



#### A/B测试
A/B测试也称为分离测试、对照试验。现在一般是指在网页优化中的一种比较策略，分离测试最开始的用法是对于同一种功能，设计两个或者多个页面并同时发布。让用户随机接触到页面，通过对日志 的埋点记录访问目标页面的人数，并计算相应的转化率或者点击率，来对不同页面进行有效评估。A/B测试主要应用一下几种情况：
  1. 产品页面或者功能控件的调整：比如通过用户路径发现用户在下单前的一个主要流量来源是用户关注对应的商家，那可以将商家有露出的某一个界面的“下单”改为“关注”，这个时候我们可以关注一下，改动之后是否比原来好。如何评判‘好坏’，需要数据分析人员和运营及产品沟通，确认相关指标，比如是单击这个功能键的UV增加了，还是对应的商户的转化率提升了等，确定后就追踪相关指标的变化。
  2. 运营策略的调整：比如做了运营活动，想看运营活动的运营效果。这时可以选定两组用户特征一模一样的用户群体，一组进行活动运营，一组保持原样。然后设定关键指标对两组用户进行追踪，比如用户的活跃、下单、付费等转化行为。或者运营想看产品定价在什么区间用户比较能够接受，也可以先用小流量测试来进行灰度发布，看不同价格的用户接受度。
A/B测试需要注意的点：
  1. 每次测试有且只有一个目标，其他变量的选取都是围绕这个目标进行的，如果有多个目标，可以进行多变量测试，或者进行多组A/B测试。
  2. 做A/B测试有个前提是流量要足够大，且参与测试的流量要能够反映出整体的实际情况。
  3. A/B测试是一个长期的过程，经过长时间的足够样本的测试结果才能接近真实结果。



### 用户运营分析
有了流量和用户之后,如何持续稳定地提升用户的活跃和留存,并对有价值的用户有针对性地进行运营,让这些用户持续稳定地为产品带来营收,这就是用户运营需要做的事情。用户运营的工作内容主要是扩大用户规模，减少用户流失，促进活跃及提高留存，增加付费转化。在用户运营的过程中数据人员要做的事情就是根据每一个模块追踪相应的指标，清楚每个指标之间的关系与影响，让每个模块的指标不管是省了还是降了，都能找到具体的原因，让运营有的放矢。
用户规模常用的指标一般是激活量与注册量，细分会有来源渠道及注册转化率。
用户流失模块主要需要定义流失，通常的做法先对产品的用户构建生命周期模型，看多长时间用户没有登录即为流失。比如有些游戏定义标准是用户90天或者180天没有登录过即为流失，而有些低频产品，如旅游类，有可能一年没有登录才定义为流失。对于如何帮助运营减少用户流失，这时需要数据根据相应指标，构建模型，弄清楚用户是在什么情况下才会流失的，当用户有此类似行为时提前告知运营，针对这批用户调整相应的运营策略，预防用户流失；针对已经流失的用户，设定特殊策略，挽回用户。
促进活跃及提高留存方面数据需要做的事情是：
1. 设定指标，比如根据产品的高频属性将每天使用产品的用户来定义活跃或者低频产品一周使用定为活跃，要给到运营可量化的指标，哪些行为时可以衡量用户活跃的，哪些行为可以促使这些行为发生。
2. 设定留存指标，需要加入对比指标，比如时间趋势的对比，或者同类产品的对比，细分留存的渠道等，让运营有针对性地设定运营策略来提升留存。
增加转化，数据可以做的事情非常多，比如筛选合适的指标，将高价值用户的特征归纳出来，并根据特征提取这批用户给到运营，让运营提供合适的运营手段来抓住这批用户的需求，让他们为产品付费，并想办法提高复购率，让他们持续稳定地付费，换句话说就是精准营销，将合适的产品推荐给合适的人。主要有两块：
1. 未付费的用户，但有付费特征，促进转化
2. 已付费的用户，让他们从低频转向高频产品，对产品产生依赖，持续不断地优化产品，提高复购率。


#### 用户分群
为什么要对用户进行分群运营？
1. 不管是一个人还是一家公司，一个网站还是一个产品，所拥有的资源都是有限的，而投资回报率需要最大化，否则就会影响企业持续稳定地发展。数据的精细化运营其实就是个性化运营，但由于资源及服务效率的限制，实际运用中我们不可能做到一对一的个性化服务，但针对不同细分群体的运营还是十分必要的。
2. 运营的过程是在用户对产品本身有需求产生的内在驱动不够的情况下，通过外在的辅助手段来增加用户体验产品的次数，或者把用户使用产品的惯性培养起来增强内在驱动，按用户分级可减少对忠诚用户的打扰，将粘性较差的用户挑选出来。
3. 通过细分群体用户进行分析，了解用户每个细分群体的变化情况，进而了解用户的整体现状及发展趋势。
对于用户细分，首要任务是根据具体的业务场景，确定不同的分类规则及指标，给出清晰的定义。可以通过简单的指标筛选或者条件限定来确认不同的用户分类，比如借鉴AARRR模型。根据用户生命周期的几个重要模块，将用户拆解如下：
我们按照业务的关键流程将用户细分为注册用户、活跃用户、留存用户、下单用户及忠诚用户。每个用户群体的细分都有独特的分析意义。
复杂一点的可以通过统计分析方法（如聚类、决策树）总结特征来显著区分不同用户群体。也有比较成熟的分析方法，如RFM模型。下面将结合传统行业中比较成熟的分析方法RFM模型来做详细的讲解。
R（Recency）代表消费新鲜度。理论上 最近一次消费时间越近，说明此用户相对来说是比较优质的用户，对提供即时的商品或者服务，他们最可能及时响应的。F（Frequency）代表消费频率，是用户在某段时间内购买商品的次数。一般来说，消费频率越大，顾客忠诚度越高。M（Monetary）代表消费金额，消费金额体现用户的消费能力。
这三个指标可以反映用户的价值。由此可见，RFM模型是针对付费用户的。假设R为用户的最近一次登录，F为一段时间的登陆次数，假设为一个月内，M为创建内容（帖子）的数量，将指标按下列规则分类：
1. 查询最近30天所有内容创建者最近一次的登陆时间。
2. 按最近一次登陆时间距离查询当日的时间排序：前20%标记为R5，记为5分。前20%~40%标记为R4，记为4分，以此类推，将创建内容的用户分成五等分。
3. 查询内容用户在一个月内的登陆天数，及创建的内容数，按同样的方法进行等分。
4. 将每个顾客对应的三个数字相加，作为内容提供用户价值的得分。
在对用户分群建立规则后，可以做以下几个方面的应用：
1. 细分用户群分析
  通过对R5、R4的用户进行建模，看能否找出活跃用户的共性，从而反推用户不活跃或者流失的原因。针对R1用户，做一些推广活动，看他们是否愿意来平台生产一些内容。对F5级别的用户进行研究，能否发现用户持续登录的原因；对F3、F4级别的用户进行研究，能否找到产品对于用户的价值；对于F1、F2的用户选取样本进行调研，看能否了解他们不登录的理由，是否可以找到产品可以改良的方法，从而知道运营。
  用某种激励措施让M5级别的用户来参与社区运营，邀请他们成为种子用户，体验新功能，给与反馈；对筛选出来的M3及M4级别的用户进行用户研究，寻找社区可以改进的点；对M1及M2的用户进行用户研究，看能否找出共性及用户沉默的原因。
2. 顾客价值模型
  基于上述用户打分规则，将用户在各维度下的得分加总。划分用户价值
| 得分 | 用户分类
|------| ------
| 14~15分| 高价值用户
| 10~13分| 优质用户
| 6~9分 | 一般用户
| 3~5分 | 低贡献用户
3. 流失用户监控模型
  针对最近登录时间距今的天数R得分及创建内容数据M得分，画像限图，
  1. R ≥ 3且M＜3， 低价值忠诚用户。
  2. R ≥ 3且M≥3， 高价值忠诚用户。
  3. R ＜ 3且M＜3， 低价值流失用户。
  4. R ＜ 3且M≥3， 高价值流失用户。

!image[流失用户群分类示意图]
根据常识，我们知道对于高价值流失用户应该尽快弄清原因，进行挽救，并对有可能是高价值流失用户的群体构建流失预警模型，在恰当的时候找出这群用户，用消息推送、精准营销等模式唤醒用户，将损失降到最小。
将低价值忠诚用户筛选出来，提供给运营，让运营对这批用户进行调研，了解他们的兴趣点及对产品的改良意见，并鼓励他们在社区发文。
4. 用户分类模型
根据用户一个月内登录的天数及用户发文数量M构建象限图，
!image[用户活跃度分类示意图]
  1. F ≥ 3且M＜3， 高活跃低价值用户。
  2. F ≥ 3且M≥3， 高活跃高价值用户。
  3. F ＜ 3且M＜3，低活跃低价值用户。
  4. F ＜ 3且M≥3， 低活跃低价值用户。
将打好的标签的用户提供给运营，让运营根据不同的需求来调整运营策略。




#### 用户行为分析
通过用户的行为分析，对用户构建用户画像，我们可以判断用户对产品的期望和喜好。互联网行业除了有业务数据之外，还有相关的日志数据，该日志体系里记录了用户在产品每一步的浏览及访问行为，这些浏览及访问行为数据整合起来形成了海量的日志数据。由于日志数据存储的都是非结构化数据，为了方便日志数据被相关人员应用，需要先对日志数据进行解析，将非结构化数据转化为结构化数据。当一个新业务上线时，业务方会和埋点组的数据同事一起沟通，将所有业务流程上的数据都一一记录下来，或者用无痕埋点的方式，将所有用户行为做记录，再根据相应的url、埋点参数等字段从解析过的日志获取用户的相关数据。
埋点日记几乎记录了用户的所有行为，其中有些指标是通用的，比如用户的访问频率、平均停留时长等；有些指标是特定场景适用的，比如盈利平台的下单行为、社区的内容发布行为等。用户行为的相关指标可分为黏性指标、参与度指标、转化类指标。
1. 黏性指标
访问频率，选取活跃用户每周的活跃天数，并按照活跃天数对用户分类，
用户的留存，用户的留存本质是产品满足用户需求。按时间分有次日留存、周留存。按渠道分有APP留存、H5留存、web留存等；按用户类型分有新用户留存、老用户留存等。新用户的留存主要取决于用户的来源渠道和产品引导。比如对老用户的留存分析可以对运营质量进行监控，对新用户的留存分析可以筛选出优质渠道。
2. 参与度指标
活跃度是评判用户参与度的一个关键指标，并没有标准定义。通常指完成某一关键动作的用户，或者参与情况满足某一条件的用户。如下单、登录、消费、使用等。我们以登录产品为活跃来距离，按时间可以拆分为日活（DAU——Daily Active User）、周活（WAU）、月活（MAU），该指标越大说明产品的打开率越高。
活跃用户的分析主要有对比分析及细分。对比分析主要看时间变化趋势及竞品数据对比。这个分析能够较直观地反映产品的用户活跃趋势，也能清楚自己产品在同类产品中的大致情况，更好地制定产品下一步的目标及走向。如果DAU有一段时间涨的明显，此时并不是数值越大越好，需要细分看这批用户的留存及转化情况。很有可能是做活动拉了一批用户，但是这批用户具体质量如何，需要进一步分析。
另外两个指标是用户的停留时长及用户的访问页面数。因为用户的停留时长可以间接反映页面对用户的吸引程度，可以间接反映产品是否满足用户的需求，及产品的设计是否合理。对于盈利性产品来说，目标就是为了转化，让用户下单，如果用户在下单前一个页面就走了，那么这个用户就没有完成转化。
比如在第三周发现用户的平均访问时长及平均访问页面两个指标急剧下降，此时需要详细定位原因，是埋点数据没有上报，还是日志解析出了问题，如果数据没有问题，那么是产品改版了还是引导机制，用户找不到入口了，还是增加了某个新流程，这些都需要数据根据逻辑设定及指标跟踪来具体定位。
3. 转化类指标
分析用户的路径转化主要有三个作用：
  1. 通过数据追踪用户的访问细节，访问细节反映的是用户的行为特征，通过追踪访问细节来推测用户的心理活动。
  2. 通过用户的访问行为来追踪用户在走流程中可能碰到的困难，看整个路径是否跟运营的设想一致，如果不一致，是哪个环节出了问题，定位具体原因，调整页面布局，
  3. 在追踪用户的访问路径的过程中，寻找有价值的可迭代路径，对产品进行优化。
分析用户的转化情况有两大方向可以着手：
  1. 从产品的整体运营情况来看，用户从激活到下单的整个流程；
  2. 从细分产品的关键路径来看，用户接触产品到完成转化经历的步骤。
通过对关键节点的数据监控，我们可以从整体及细分渠道、细分时间、细分活动来看不同的转化情况，找出有问题的节点，



#### 用户生命周期
用户的生命周期一般会经理引入期、成长期、成熟期、衰退期、流失期等五个阶段，每个阶段都会为产品带来不同的价值。
- 引入期：此时用户刚来，用户会试探性地试用产品，偶尔用一下，此时用户的价值相对来说比较低。
- 成长期：用户会不定期地来试用产品，并开始进一步体验产品功能，此时用户的价值有所上升。
- 成熟期：用户会经常使用产品，并会以分享形式来宣传产品，此时用户的价值比较大。
- 衰退期：用户因某些原因不再经常使用产品，此时用户的价值呈现衰减模式。
- 流失期：用户对产品非常不满意，不再登录该产品。
在用户运营的过程中，我们不能一上来就唯周期论，而是要定一个目标，围绕目标我们能拆解哪些关键指标，要提升这些关键指标需要去满足用户什么核心需求。比如用户周期分析的核心目标是：提升用户生命周期每个节点的转化率，提升用户的留存。
LTV = （某个用户 每个月的下单频次 * 客单价 * 毛利率） * （1 / 月流失率）
    = （某个客户每个月的下单频次 * ARPU * 毛利率）* （1 / （1 - 月留存率））
    = 用户生命周期内下单次数 * 客单价 * 毛利率

其中：
1. ARPU(每个用户的平均收入) = 某段时间内的总收入 / 同时期内活跃用户总数
2. 流失率 = 在某段时间内流失的用户 / 同时期内活跃用户总数
3. 流失率的倒数是用来表示预测的用户生命周期

应用一、根据拆解指标为提升LTV制定不同的运营策略
  从拆解公式看，运营需要的是尽可能保证渠道的质量，确保引进来的用户的有效性，提升用户的质量及数量，尽量降低获取用户的成本，并应用多样化的运营手段提升用户转化；在生命周期的每个时间周期，对不同结构的用户进行流失原因分析，提升用户活跃。

应用二、评估用户运营活动是否盈利
  单个用户毛利 = 用户生命周期价值 - 获取用户成本 - 运营成本 = CLV - CAC - COC
  很多产品在初期一直补贴用户的形式留住用户，长此以往，资金链一断裂将无以为继，只有到用户的毛利率大于0时，产品才能持续地发展下去。

应用三、追踪投资回报率
  根据LTV的公式及用户毛利的计算公式。得到：
  ROI = 转化率 * ARPU/（CAC + COC）
  1. 提高转化率
  提高转化率，一要不断通过各种方式来获取新用户，二要减少产品的用户流失，及挽回即将流失或者已经流失的用户。如何挽回如下：
    1. 从产品出发，首先要通过现有的指标找出用户是在哪步流失的，再结合具体的产品进行改进。
    2. 从运营出发，形成种子用户群体，保证流失下限，结合具体的运营策略，如抽奖等。
  2. 提高ARPU
  提高ARPU可以从抓用户的需求来展开。
    1. 发放优惠券，来满足用户的占便宜心里，促进用户下单。
    2. 对用户设立等级体系，并对不同的用户等级设立不同的福利规则，满足用户对身份高人一等的诉求。
    3. 建立精准营销平台，精准定位用户群体，并对这部分群体进行个性化精准推荐，满足用户的特定场景需求。
    4. 提示用户信息不会被泄露，满足用户对安全感的诉求。
    5. 生日提供满减或其他福利，满足用户对情感的认同需求。
  3. 降低成本
    1. 降低用户获取成本
      1. 通过数据分析优化渠道质量
      2. 通过流失预警，对即将流失的用户进行合适运营，提高用户留存，增加用户对产品的参与度与黏性
      3. 与其他平台合作，资源共享
    2. 降低用户的运营成本
      1. 搭建精准营销平台，对每个用户的各个属性进行打标，对高金值客户推送单价高的商品
      2. 建立常用分析思路的BI报表，并支持快速迭代。




## 数据管理模板

### Excel


### PPT






## 用户画像

### 用户画像简介
用户画像是大数据技术的一种重要应用方式。建立用户画像所用的数据源是与用户相关的全部数据，包括用户的属性数据、行为数据及内容数据，其中属性数据表示包括用户性别、年龄、地域等用户自身固有的属性，这类数据可以在用户注册、填写各类表单的环节中收集；行为数据描述用户所执行的行为，包括访问次数、访问停留时间、加关注、加入购物车、取出购物车、形成订单、付款等；内容数据表示用户行为的对象，如用户加关注、加入购物车、形成订单所对应的商品。这些数据源构成了建立用户画像模型的基础。
用户画像，即用户信息标签化，通过收集用户社会属性、消费习惯、偏好特征等各个维度的数据，对用户或者产品特征属性进行刻画，并对这些特征进行分析、统计来挖掘潜在价值信息，从而抽象出一个用户的信息全貌。用户画像可看作企业应用大数据的根基，是定向广告投放于个性化推荐的前置条件，为数据驱动运营奠定了基础。如何从海量数据中挖掘出有价值的信息已经愈发重要。
用户画像建模其实就是为用户打标签。为用户打的标签分为三种：基于统计类的标签、基于规则类的标签和基于挖掘类的标签。在开发用户画像建立的过程中要用的数据非常多，按数据粒度及应用场景大体分为三个层级：
- 明细层数据：以“日”为数据粒度，直接从各个业务数据表、日志数据表、埋点数据表抽取用户每天的每一次行为，按固定表结构插入相关表中，在此过程中不对数据做任何汇总、统计类的处理。可视为数据仓库中ODS层数据。如用户行为标签日表、用户活跃行为日表、用户消费日表、用户属性表。
- 统计中间层数据：以“用户”为数据粒度，对明细层的全量历史数据进行统计加工、汇总计算，可视为数据仓库中DW层数据。如用户活跃个性化标签表、用户消费个性化标签表、用户内容个性化标签表。
- 应用层（DM层) ：以“用户”为数据粒度，对统计中间层数据做进一步挖掘处理，处理过程中要考虑业务应用场景，关联行为权重、标签权重等。应用层数据输出后可支持产品应用。
开发出的用户画像相关宽表及明细标签表,按应用场景一般分为用户人口属性画像、用户个性化标签、各业务线用户画像、用户偏好画像和用户群体属性画像等。
- 用户人口属性画像
用户在平台注册账号或者填写收货地址时会填写的基础信息，如性别、年龄、城市、行业等。用户人口属性画像是对用户静态属性刻画的重要依据，所以对基础信息的真实性要求更为严格。
- 用户个性化标签
用户在产品上的浏览、搜索、关注、收藏等行为会带来一系列标签。根据这些标签的发生时间、行为次数、行为类型能够统计出用户与某些标签之间的联系的紧密程度。
- 个业务线用户画像
针对各业务线的业务特征，设计一套标签用于监控用户在该业务线上的操作行为。
- 用户偏好画像
在用户个性化标签的基础上，根据业务规则设定用户各种行为类型的权重、时间衰减方式、标签权重，并通过基于物品相关的协同过滤算法建立用户偏好画像的数据表。
- 群体属性画像
 可按照用户性别、年龄、省份等基础信息划分，也可按照用户消费频率、消费能力等行为属性划分。

### 用户画像管理
用户画像数据需要结合业务需求进行开发，我们将从模块化开发、存储方式、更新机制三个方面进行介绍。
#### 模块化开发
一套完整的用户标签体系涉及许多人员，而且也不是一两天的事情，它牵涉着产品经理、运营人员、数据分析挖掘人员数据仓库的ETL开发人员等。虽然数据挖掘人员的工作核心在于标签的业务建模，但是其中的开发和维护工作，需要协同产品经理、运营方和开发方来展开。
在用户画像开发前需要考虑到随着业务的不断发展，画像开发人员随时都可能面临新增标签类型的需求。在接到新需求是，是否要重新单独构建一套模型去适应业务的不断发展？当然不是，我们需要用模块化思维去进行画像的开发。模块化开发可以在有限的资源里高效、快捷地进行标签模型开发及后续的迭代。将画像工程划分成很多功能独立的模块，再进行迭代、重构和维护等工作时，只需要针对具体的模块进行处理，不需要重新构建模型。
具体来说，用户画像需要结合业务需求进行开发。从应用角度看，标签主要可分为两大类——通用标签和业务类标签。
通用类标签是从源业务标签表抽取并经过初步统计得到的标签，这类标签还未与业务深度结合，做出来的标签无法直接服务于各业务单元。但是其为建立面向各业务场景的相关标签打下了基础，是前置条件。比如，用户基础信息表记录了用户性别、年龄、地域等属性，通过人口属性刻画，可达到对用户初步认知的目的；用户行为标签标签表记录了用户在产品使用过程中浏览、关注、收藏、搜索等行为的时间、行为次数。各业务标签都是在通用标签表的基础上结合业务进行深度加工、挖掘得到的。
业务类标签服务于各项业务属性，如在产品的“推荐”或”猜你喜欢”板块上推荐与用户属性相关的内容。在这类标签开发的过程中数据放需要与运营方深入沟通需求，明确业务场景、应用方式与推荐规则，明确标签种类与行为权重，再结合推荐产品的类型才能给用户打上相应的属性标签。
从类型角度看，标签可分为个人用户画像和群体用户画像。前者主要用于用户个性化定位，而后者用于对用户群体的定位。群体用户画像的建立都是基于个人的用户画像建立的，即先建立个人用户的画像（根据每人的标签与对应的权重弄确定属性值），而后建立的群体画像（统计各属性值在各属性中所占的比例）。
#### 存储方式
Hive数据仓库较为适合用户画像的存储、管理与分析。采用数据仓库技术不仅可以管理海量用户画像数据，而且可以通过有效地综合分析进一步挖掘数据的潜在价值。画像建模人员通过数据仓库的相关业务表、日志表、埋点表中抽取与用户基础属性、行为属性、消费属性等相关的数据进行建模加工，输出用户人口属性表、用户个性化标签表等用户画像相关表，并将这些画像表重新写回数据仓库中，以便后续的应用。
Hive数据仓库封装用户画像模型的各明细表和宽表，各业务方及运营方可通过直接访问数据库或者登录数据提取平台的方式，访问画像模型数据宽表。也可以通过线上展示平台配置用户分群规则，提取相关用户标签，实时反馈运营及营销接触数据问题，整合并更新画像模型。通过配置分析及应用平台可视化展示推荐标签库，以实现权限管控。
#### 跟新机制
一个简单的用户信息标签表就会有成千上百个特征标签，其中有些特征标签在短期内是不变的，如用户的性别、年龄等基础信息；有些事随时间变化的，如用户的浏览、关注等行为指标。此外，随着产品业务线的不断拓展，以及更详细的划分维度，这些标签的特征类型可能会增加。因此，有效地用户画像需要不断地进行完善和更新。
在画像开发过程中，使用欧冠HQL语言将建模后的各维度用户画像表写入Hive，在Hive中建立分区表，以当天日期作为分区依据，每天定时刷新前一天运营产生的数据，增量插入数据已建立的画像表中。






### 案例
#### 北京介绍
电商网站。用户在平台上可进行浏览、搜索、收藏、下单购买等行为。商城的运营需要解决两个问题：在企业产品线逐渐扩张、信息资源过载的背景下如何在兼顾自身商业目标的同时更好地满足消费者的需求，为用户带来更个性化的购物体验，并通过内容的精准推荐，更好地提高用户的单击转化率；在用户规模不断增长的背景下，运营方考虑建立用户流失预警机制，以及识别出将要流失的用户群体，采取运营措施进行用户挽回。

#### 相关表的介绍
可以获取的数据主要有两种：
- 业务类数据：用户在平台上下单、购买、收藏物品等与业务相关的数据。
- 用户行为数据：用户搜索某条信息、访问某个页面、单击某个按钮等通过操作行为产生的数据。
涉及数据仓库中的表主要包括：用户信息表、商品订单表、图书信息表、图书类目表、APP端日志表、WEB端日志表、商品评论表等。
用户信息表存放着用户的各种信息，如用户姓名、年龄、性别、号码、归属地等信息。
商品订单表存放着商品订单的各种信息，如订单编号、用户id、用户姓名、订单生产时间、订单状态等。
图书信息表存放着图书名称、作者、出版社、价格、页数、出版时间等信息。
图书类目表存放着图书归属类别信息，可通过图书id与图书信息表建立联系。
web端日志表存放着用户访问web页面的信息及用户的LBS相关信息（基于位置的服务），通过在客户端做埋点，从日志数据解析出来。
APP端日志表存放着用户访问APP的页面的信息及用户的LBS相关信息（基于位置的服务），通过在客户端做埋点，从日志数据解析出来。
商品评论表存放着用户对商品的评论信息。
搜索日志表存放用户在APP端进行搜索的相关日志数据。
用户收藏表记录用户收藏图书数据

#### 用户画像建模
#### 业务需求梳理
需要开发的用户标签体系包括
- 用户个人标签：用户属性标签、用户行为标签、用户偏好图书标签
- 用户群体标签：用户群组图书标签top10排序

用户偏好表是使用TF-IDF算法计算的每个标签的自身权重大小。



























































0.0
